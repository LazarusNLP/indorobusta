{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4941366e-c680-4626-bdfd-fe293ac4fb9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as axes\n",
    "import numpy as np\n",
    "from matplotlib.pyplot import figure\n",
    "import pandas as pd\n",
    "# import matplotlib.pyplot as plt\n",
    "# import matplotlib\n",
    "from matplotlib.pyplot import figure, xticks\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from deep_translator import GoogleTranslator\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "# plt.rcParams['axes.facecolor'] = 'white'\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4083ca53-b502-4bea-a994-e94562f7220a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xlmr-sentiment-codemixing-fr-adv-0.8-train\n"
     ]
    }
   ],
   "source": [
    "model_target = \"xlmr\"\n",
    "downstream_task = \"sentiment\"\n",
    "attack_strategy = \"codemixing\"\n",
    "perturbation_technique = \"adv\"\n",
    "perturb_ratio = 0.8\n",
    "dataset = \"train\"\n",
    "perturb_lang = \"fr\"\n",
    "seed = 26092020\n",
    "\n",
    "finetune_epoch = 0\n",
    "if downstream_task == \"sentiment\":\n",
    "    finetune_epoch = 5\n",
    "if downstream_task == \"emotion\":\n",
    "    finetune_epoch = 10\n",
    "\n",
    "exp_name = model_target+\"-\"+downstream_task+\"-\"+attack_strategy+\"-\"+perturb_lang+\"-adv\"+\"-\"+str(perturb_ratio)+\"-\"+dataset\n",
    "# exp_name = \"indobert-emotion-codemixing-en-adv-0.2-train\"\n",
    "print(exp_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c0a1bcee-635c-43b0-93ef-27e5beca4c0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>perturbed_text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>décrochage en bordure de route ini possédé oleh homme d'affaire usine tahu yang sudah douzaines tahun célèbre membuat tahu blanche di Bandung tahu qualité combiné compétence memasak combiné la créativité jadilah décrochage en bordure de route yang menyajikan menu utama fait à partir de tahu ditambah menu umum lain seperti ayam semuanya appétit Indonésie le prix cukup abordable jangan Mademoiselle tahu bletoka le sien tidak perdu dengan yang asli dari domaine</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mohon clerc droit dan k212 mmbri preuve faire la fête apa yang harus diwlh agar voix islam tidak</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lokasi stratégique di jalan Sumatra Bandung tempat le sien nyaman terutama sofa di étage 2 Paëlla le sien joli sangat en forme dimakan dengan boire Bière du froid apéritif le sien juga</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>comment bahagia le sien diri ini saat déballage emballer dan des biens le sien bon Positionner acheter lagi</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>duh jadi étudiant jangan fier dong amour carte Jaune segala étude dulu yang baik tidak usahlah politique nanti sudah Fini en train d'étudier le sien mau ikut politique juga tidak telat base étudiant</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10995</th>\n",
       "      <td>tidak déçu</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10996</th>\n",
       "      <td>enak rasa Cuisiner le sien apalagi Crabe yang agréable kita choisir Crabe le sien sendiri dan masih Frais selalu arrêtez-vous ke sini kalau setiap ke bandung</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10997</th>\n",
       "      <td>respect yang telah berkoalisi</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10998</th>\n",
       "      <td>Matin Matin di péage pasteur sudah congestionné critique Fabriquer jengkel saja ini</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10999</th>\n",
       "      <td>meskipun sering achats ke yoga di Riau jonction tapi baru pertama temps ini saya voir la vie alimentaire tempat le sien grande dan faire le ménage tidak taudis semacam aire de restauration lainnya dan choix aliments le sien banyak très dari yang traditionnel sampai aliments Ouest ataupun asian mau yang lourd sampai ke yang léger hampir semuanya ada tinggal sélectionner dan disesuaikan sama biaya makan le sien saja</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                       perturbed_text  \\\n",
       "0      décrochage en bordure de route ini possédé oleh homme d'affaire usine tahu yang sudah douzaines tahun célèbre membuat tahu blanche di Bandung tahu qualité combiné compétence memasak combiné la créativité jadilah décrochage en bordure de route yang menyajikan menu utama fait à partir de tahu ditambah menu umum lain seperti ayam semuanya appétit Indonésie le prix cukup abordable jangan Mademoiselle tahu bletoka le sien tidak perdu dengan yang asli dari domaine   \n",
       "1                                                                                                                                                                                                                                                                                                                                                                                    mohon clerc droit dan k212 mmbri preuve faire la fête apa yang harus diwlh agar voix islam tidak   \n",
       "2                                                                                                                                                                                                                                                                                            lokasi stratégique di jalan Sumatra Bandung tempat le sien nyaman terutama sofa di étage 2 Paëlla le sien joli sangat en forme dimakan dengan boire Bière du froid apéritif le sien juga   \n",
       "3                                                                                                                                                                                                                                                                                                                                                                         comment bahagia le sien diri ini saat déballage emballer dan des biens le sien bon Positionner acheter lagi   \n",
       "4                                                                                                                                                                                                                                                                              duh jadi étudiant jangan fier dong amour carte Jaune segala étude dulu yang baik tidak usahlah politique nanti sudah Fini en train d'étudier le sien mau ikut politique juga tidak telat base étudiant   \n",
       "...                                                                                                                                                                                                                                                                                                                                                                                                                                                                               ...   \n",
       "10995                                                                                                                                                                                                                                                                                                                                                                                                                                                                      tidak déçu   \n",
       "10996                                                                                                                                                                                                                                                                                                                   enak rasa Cuisiner le sien apalagi Crabe yang agréable kita choisir Crabe le sien sendiri dan masih Frais selalu arrêtez-vous ke sini kalau setiap ke bandung   \n",
       "10997                                                                                                                                                                                                                                                                                                                                                                                                                                                   respect yang telah berkoalisi   \n",
       "10998                                                                                                                                                                                                                                                                                                                                                                                             Matin Matin di péage pasteur sudah congestionné critique Fabriquer jengkel saja ini   \n",
       "10999                                               meskipun sering achats ke yoga di Riau jonction tapi baru pertama temps ini saya voir la vie alimentaire tempat le sien grande dan faire le ménage tidak taudis semacam aire de restauration lainnya dan choix aliments le sien banyak très dari yang traditionnel sampai aliments Ouest ataupun asian mau yang lourd sampai ke yang léger hampir semuanya ada tinggal sélectionner dan disesuaikan sama biaya makan le sien saja   \n",
       "\n",
       "       sentiment  \n",
       "0              0  \n",
       "1              1  \n",
       "2              0  \n",
       "3              0  \n",
       "4              2  \n",
       "...          ...  \n",
       "10995          0  \n",
       "10996          0  \n",
       "10997          1  \n",
       "10998          2  \n",
       "10999          0  \n",
       "\n",
       "[11000 rows x 2 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = os.getcwd() + r'/result/seed'+str(seed)+\"/\"+str(dataset)+\"/\"+str(exp_name)+\".csv\"\n",
    "df = pd.read_csv(path)\n",
    "df = df[[\"perturbed_text\", \"sentiment\"]]\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8f4e9e95-6bd3-4cc1-8662-9f2564928001",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['xlmr-emotion-sr-adv-0.8-train.csv',\n",
       " 'indobert-emotion-codemixing-jw-adv-0.8-train.csv',\n",
       " 'xlmrlarge-emotion-sr-adv-0.8-train.csv',\n",
       " 'mbert-emotion-codemixing-jw-adv-0.8-train.csv',\n",
       " 'xlmr-emotion-codemixing-ms-adv-0.8-train.csv',\n",
       " 'indobertlarge-emotion-sr-adv-0.8-train.csv',\n",
       " 'indobert-emotion-codemixing-en-adv-0.2-train.csv',\n",
       " 'indobert-emotion-codemixing-ms-adv-0.8-train.csv',\n",
       " 'indobertlarge-emotion-codemixing-su-adv-0.8-train.csv',\n",
       " 'indobert-emotion-codemixing-it-adv-0.8-train.csv',\n",
       " 'indobert-emotion-codemixing-fr-adv-0.8-train.csv',\n",
       " 'xlmr-sentiment-codemixing-it-adv-0.8-train.csv',\n",
       " 'indobert-emotion-codemixing-su-adv-0.8-train.csv',\n",
       " 'indobertlarge-emotion-sr-adv-0.2-train.csv',\n",
       " 'indobertlarge-emotion-codemixing-en-adv-0.8-train.csv',\n",
       " 'xlmr-emotion-codemixing-en-adv-0.2-train.csv',\n",
       " 'indobertlarge-emotion-codemixing-fr-adv-0.8-train.csv',\n",
       " 'mbert-sentiment-sr-adv-0.8-train.csv',\n",
       " 'xlmr-emotion-sr-adv-0.2-train.csv',\n",
       " 'xlmrlarge-sentiment-sr-adv-0.8-train.csv',\n",
       " 'xlmr-sentiment-codemixing-fr-adv-0.8-train.csv',\n",
       " 'xlmr-emotion-codemixing-it-adv-0.8-train.csv',\n",
       " 'indobert-emotion-codemixing-en-adv-0.8-train.csv',\n",
       " 'xlmrlarge-emotion-codemixing-en-adv-0.8-train.csv',\n",
       " '.ipynb_checkpoints',\n",
       " 'indobert-emotion-sr-adv-0.2-train.csv',\n",
       " 'indobert-sentiment-sr-adv-0.8-train.csv',\n",
       " 'indobert-emotion-codemixing-ms-adv-0.2-train.csv',\n",
       " 'indobert-emotion-codemixing-fr-adv-0.2-train.csv',\n",
       " 'indobertlarge-emotion-codemixing-it-adv-0.8-train.csv',\n",
       " 'xlmr-emotion-codemixing-jw-adv-0.8-train.csv',\n",
       " 'mbert-emotion-codemixing-en-adv-0.8-train.csv',\n",
       " 'indobertlarge-emotion-codemixing-ms-adv-0.8-train.csv',\n",
       " 'xlmr-emotion-codemixing-it-adv-0.2-train.csv',\n",
       " 'indobert-emotion-codemixing-su-adv-0.2-train.csv',\n",
       " 'indobert-emotion-sr-adv-0.8-train.csv',\n",
       " 'xlmr-emotion-codemixing-su-adv-0.8-train.csv',\n",
       " 'indobert-emotion-codemixing-jw-adv-0.2-train.csv',\n",
       " 'xlmrlarge-emotion-codemixing-su-adv-0.8-train.csv',\n",
       " 'xlmrlarge-emotion-codemixing-jw-adv-0.8-train.csv',\n",
       " 'xlmr-sentiment-sr-adv-0.8-train.csv',\n",
       " 'xlmr-emotion-codemixing-fr-adv-0.8-train.csv',\n",
       " 'mbert-emotion-sr-adv-0.8-train.csv',\n",
       " 'xlmr-emotion-codemixing-en-adv-0.8-train.csv',\n",
       " 'indobertlarge-emotion-codemixing-jw-adv-0.8-train.csv']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from icecream import ic\n",
    "\n",
    "dataset = \"valid\"\n",
    "\n",
    "path_train = str(os.getcwd()) + \"/result/seed\" + str(seed) + \"/\" + \"train\" + \"/\"\n",
    "path_valid = str(os.getcwd()) + \"/result/seed\" + str(seed) + \"/\" + \"valid\" + \"/\"\n",
    "\n",
    "dir_list_train = os.listdir(path_train)\n",
    "dir_list_valid = os.listdir(path_valid)\n",
    "\n",
    "\n",
    "dir_list_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1dbc9550-2b22-4a19-ae3d-20c440cbe06d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_reader(path):\n",
    "    a_file = open(path, \"r\")\n",
    "\n",
    "    vocab = []\n",
    "    for line in a_file:\n",
    "        stripped_line = line.strip()\n",
    "        vocab.append(stripped_line)\n",
    "\n",
    "    a_file.close()\n",
    "    return list(set(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b2f39034-ff45-4030-b735-130f58301351",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "que\n",
      "5718\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "  \n",
    "# reading the data from the file\n",
    "with open('dict_fr.txt') as f:\n",
    "    data = f.read()\n",
    "      \n",
    "# reconstructing the data as a dictionary\n",
    "d = ast.literal_eval(data)\n",
    "print(d['kamu'])\n",
    "same_val = []\n",
    "for k in d.keys():\n",
    "    if k == d[k]:\n",
    "        # print(k, d[k])\n",
    "        same_val.append(k)\n",
    "\n",
    "print(len(same_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "26712731-33b2-4af5-970c-cfdd45a6e576",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_dict(filename):\n",
    "    with open(filename) as f:\n",
    "        data = f.read()\n",
    "      \n",
    "    # reconstructing the data as a dictionary\n",
    "    d = ast.literal_eval(data)\n",
    "    # print(type(d))\n",
    "    return d\n",
    "\n",
    "def translate_batch(wordlist,translator, online_trans):\n",
    "    translated = []\n",
    "    print(wordlist)\n",
    "    for w in wordlist:\n",
    "        # print(translator[w])\n",
    "        if w in translator.keys():\n",
    "            trans = translator[w]\n",
    "        else:\n",
    "            trans = online_trans.translate(w)\n",
    "        translated.append(trans)\n",
    "        \n",
    "    return translated\n",
    "\n",
    "def trans_dict_cache(wordlist, lang=None):\n",
    "    \n",
    "    translator = read_dict(os.getcwd() + r\"/dicts/dict_\"+lang+\".txt\")\n",
    "    online_trans = GoogleTranslator(source=\"id\", target=target_lang)\n",
    "    new_wp = []\n",
    "    for wp in words_perturb:\n",
    "        if wp[1].isalpha():\n",
    "            new_wp.append(wp[1])\n",
    "    \n",
    "    if len(new_wp) == 1:\n",
    "        new_wp_trans = dict(zip(new_wp, translator[new_wp[0]]))\n",
    "    elif len(new_wp) == 0:\n",
    "        return ' '.join(words), {}\n",
    "        \n",
    "    new_wp_trans = dict(zip(new_wp, translator.translate_batch(new_wp)))\n",
    "    \n",
    "    supported_langs = [\"su\", \"jw\", \"ms\", \"en\", \"fr\", \"it\"]\n",
    "    \n",
    "    if target_lang not in supported_langs:\n",
    "        raise ValueError('Language Unavailable')\n",
    "    \n",
    "    new_words = words.copy()\n",
    "    \n",
    "    if len(words_perturb) >= 1:\n",
    "        for perturb_word in new_wp_trans.keys():\n",
    "            new_words = [new_wp_trans[perturb_word] if word == perturb_word and word.isalpha() else word for word in new_words]\n",
    "\n",
    "    return ' '.join(new_words), new_wp_trans\n",
    "#     translated_wordlist = {}\n",
    "#     # ic(wordlist)\n",
    "#     supported_langs = [\"su\", \"jw\", \"ms\", \"en\", \"fr\", \"it\"]\n",
    "    \n",
    "#     if lang not in supported_langs:\n",
    "#         raise ValueError('Language Unavailable')\n",
    "    \n",
    "#     translator = read_dict(os.getcwd() + r\"/dicts/dict_\"+lang+\".txt\")\n",
    "#     online_trans = GoogleTranslator(source=\"id\", target=lang)\n",
    "#     # translator = GoogleTranslator(source=\"id\", target=lang)\n",
    "    \n",
    "#     alpha = []\n",
    "#     non_alpha = {}\n",
    "#     for word in wordlist:\n",
    "#         if word.isdigit():\n",
    "#             non_alpha[word] = word\n",
    "#         elif any(c.isalpha() for c in word):\n",
    "#             alpha.append(word)\n",
    "#         else:\n",
    "#             non_alpha[word] = word\n",
    "    \n",
    "#     # trans_alpha = translate_batch(alpha,translator)\n",
    "#     translated_alpha = dict(zip(alpha, translate_batch(alpha,translator,online_trans)))\n",
    "\n",
    "#     translated_wordlist = {**non_alpha, **translated_alpha}\n",
    "#     # if len(translated_wordlist)%10 == 0:\n",
    "#     return translated_wordlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "55dec143-b770-4cb4-913b-d9a64457d81b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ai']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'ai': 'ai'}"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trans_dict_cache(['ai'], 'su')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "b39aa6df-2a3a-41be-9072-f9c4b5d3e03e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/raid/data/m13518040/tugas-akhir-repository'"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.getcwd()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
