{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c40616b8-d0c2-43c6-ab5b-7b48673ded38",
   "metadata": {},
   "source": [
    "# Demo Tugas Akhir 2\n",
    "---\n",
    "Berikut adalah demo implementasi solusi Tugas Akhir 2 Pengujian Adversarial Robustness pada Model Bahasa Pra-latih dalam Domain Klasifikasi Teks. Dalam demo ini seluruh komponen dalam rancangan solusi telah diimplementasikan pada package yang diimport pada cell pertama."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "334ce266-dfda-4d3d-88d3-6d940ab16ef1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, sys\n",
    "import gc\n",
    "\n",
    "gc.collect()\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "import swifter\n",
    "import torch\n",
    "device = torch.device(\"cuda\")\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "from utils.utils_init_dataset import set_seed, load_dataset_loader\n",
    "from utils.utils_semantic_use import USE\n",
    "from utils.utils_data_utils import DocumentSentimentDataset, DocumentSentimentDataLoader, EmotionDetectionDataset, EmotionDetectionDataLoader\n",
    "from utils.utils_metrics import document_sentiment_metrics_fn\n",
    "from utils.utils_init_model import text_logit, fine_tuning_model, eval_model, init_model, logit_prob, load_word_index\n",
    "from utils.get_args import get_args\n",
    "\n",
    "from attack.adv_attack import attack\n",
    "import os, sys"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44339401-e007-4442-a8ba-8df4e0f01e2e",
   "metadata": {},
   "source": [
    "### Deklarasi variabel untuk pengujian\n",
    "---\n",
    "Pada pengujian kali ini dilakukan terhadap model IndoBERT-Base untuk task analisis sentimen dengan code-mixing Bahasa Perancis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "953e4fa2-9928-4c78-804d-271b6f308f59",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_target = \"IndoBERT\"\n",
    "downstream_task = \"sentiment\"\n",
    "attack_strategy = \"adversarial\"\n",
    "finetune_epoch = 10\n",
    "num_sample = 10\n",
    "exp_name = \"demo\"\n",
    "perturbation_technique = \"codemixing\"\n",
    "perturb_ratio = 0.6\n",
    "dataset = \"valid\"\n",
    "perturb_lang=\"fr\"\n",
    "seed=26092020"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1209281c-27f3-42fa-b9cd-96e2fc55a496",
   "metadata": {},
   "source": [
    "### Inisialisasi Pengujian\n",
    "---\n",
    "Pada tahap ini diinisialisasi random seed yang digunakan, kemudian inisialisasi model Universal Sentence Encoder, inisialisasi model, dan inisialisasi dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d3b73bcf-63ff-4f72-bc51-d1f7a7d5e6e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertForSequenceClassification(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(50000, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (2): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (3): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (4): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (5): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (6): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (7): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (8): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (9): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (10): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (11): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=768, out_features=3, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_seed(seed)\n",
    "use = USE()\n",
    "\n",
    "tokenizer, config, finetuned_model = init_model(model_target, downstream_task, seed)\n",
    "w2i, i2w = load_word_index(downstream_task)\n",
    "\n",
    "train_dataset, train_loader, train_path = load_dataset_loader(downstream_task, 'train', tokenizer)\n",
    "valid_dataset, valid_loader, valid_path = load_dataset_loader(downstream_task, 'valid', tokenizer)\n",
    "test_dataset, test_loader, test_path = load_dataset_loader(downstream_task, 'test', tokenizer)\n",
    "\n",
    "finetuned_model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75e7fb79-9e56-41d7-8e6b-c333f23f343a",
   "metadata": {},
   "source": [
    "### Tahap Pengujian\n",
    "--- \n",
    "Dilakukan pengujian dengan parameter yang telah didefinisikan sebelumnya. Pengujian dilakukan secara iteratif pada dataset validasi menggunakan fungsi adversarial attack yang telah diimport pada package diatas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "28153c7b-1259-495f-8707-d4cc9135a576",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████| 10/10 [00:47<00:00,  4.72s/it]\n"
     ]
    }
   ],
   "source": [
    "if dataset == \"valid\":\n",
    "    exp_dataset = valid_dataset.load_dataset(valid_path).sample(num_sample)\n",
    "elif dataset == \"train\":\n",
    "    exp_dataset = train_dataset.load_dataset(train_path)\n",
    "    \n",
    "text,label = None,None\n",
    "\n",
    "if downstream_task == 'sentiment':\n",
    "    text = 'text'\n",
    "    label = 'sentiment'\n",
    "    exp_dataset[['perturbed_text', 'perturbed_semantic_sim', 'pred_label', 'pred_proba', 'perturbed_label', 'perturbed_proba', 'translated_word(s)', 'running_time(s)']] = exp_dataset.progress_apply(\n",
    "        lambda row: attack(\n",
    "            text_ls = row.text,\n",
    "            true_label = row.sentiment,\n",
    "            predictor = finetuned_model,\n",
    "            tokenizer = tokenizer, \n",
    "            att_ratio = perturb_ratio,\n",
    "            perturbation_technique = perturbation_technique,\n",
    "            lang_codemix = perturb_lang,\n",
    "            sim_predictor = use), axis=1, result_type='expand'\n",
    "    )\n",
    "elif downstream_task == 'emotion':\n",
    "    text = 'tweet'\n",
    "    label = 'label'\n",
    "    exp_dataset[['perturbed_text', 'perturbed_semantic_sim', 'pred_label', 'pred_proba', 'perturbed_label', 'perturbed_proba', 'translated_word(s)', 'running_time(s)']] = exp_dataset.progress_apply(\n",
    "        lambda row: attack(\n",
    "            text_ls = row.tweet,\n",
    "            true_label = row.label,\n",
    "            predictor = finetuned_model,\n",
    "            tokenizer = tokenizer, \n",
    "            att_ratio = perturb_ratio,\n",
    "            perturbation_technique = perturbation_technique,\n",
    "            lang_codemix = perturb_lang,\n",
    "            sim_predictor = use), axis=1, result_type='expand'\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f510614-9943-4d9c-9b8f-ef730a0d1a4e",
   "metadata": {},
   "source": [
    "### Tahap Evaluasi\n",
    "---\n",
    "Pada tahap ini dilakukan evaluasi dari adversarial examples dan label prediksi yang telah dihasilkan pada cell sebelumnya. Pengujian dilakukan dengan melihat delta akurasi dan skor kemiripan semantik."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c3700ece-9ca3-41b0-bbf5-7ddd3c01251d",
   "metadata": {},
   "outputs": [],
   "source": [
    "before_attack = accuracy_score(exp_dataset[label], exp_dataset['pred_label'])\n",
    "after_attack = accuracy_score(exp_dataset[label], exp_dataset['perturbed_label'])\n",
    "\n",
    "exp_dataset.loc[exp_dataset.index[0], 'before_attack_acc'] = before_attack\n",
    "exp_dataset.loc[exp_dataset.index[0], 'after_attack_acc'] = after_attack\n",
    "exp_dataset.loc[exp_dataset.index[0], 'delta_acc'] = before_attack-after_attack\n",
    "exp_dataset.loc[exp_dataset.index[0], 'avg_semantic_sim'] = exp_dataset[\"perturbed_semantic_sim\"].mean()\n",
    "exp_dataset.loc[exp_dataset.index[0], 'avg_running_time(s)'] = exp_dataset[\"running_time(s)\"].mean()\n",
    "# exp_dataset.to_csv(os.getcwd() + r'/result/seed'+str(seed)+\"/\"+str(dataset)+\"/\"+str(exp_name)+\".csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "cfeb32f3-4ea2-414e-a9ff-802859d2ca6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>perturbed_text</th>\n",
       "      <th>perturbed_semantic_sim</th>\n",
       "      <th>pred_label</th>\n",
       "      <th>pred_proba</th>\n",
       "      <th>perturbed_label</th>\n",
       "      <th>perturbed_proba</th>\n",
       "      <th>translated_word(s)</th>\n",
       "      <th>running_time(s)</th>\n",
       "      <th>before_attack_acc</th>\n",
       "      <th>after_attack_acc</th>\n",
       "      <th>delta_acc</th>\n",
       "      <th>avg_semantic_sim</th>\n",
       "      <th>avg_running_time(s)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>saya jadi tidak simpati lagi sama nikita mirza...</td>\n",
       "      <td>2</td>\n",
       "      <td>saya jadi tidak sympathie lagi sama nikita mir...</td>\n",
       "      <td>0.863004</td>\n",
       "      <td>2</td>\n",
       "      <td>[0.0011, 0.0012, 0.9976]</td>\n",
       "      <td>2</td>\n",
       "      <td>[0.0412, 0.0089, 0.9499]</td>\n",
       "      <td>{'blokir': 'bloc', 'simpati': 'sympathie', 'me...</td>\n",
       "      <td>1.4578</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.835196</td>\n",
       "      <td>4.71789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>914</th>\n",
       "      <td>cocok buat makan buat yang punya teman banyak ...</td>\n",
       "      <td>0</td>\n",
       "      <td>cocok buat makan buat yang punya ami banyak ic...</td>\n",
       "      <td>0.901243</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.9982, 0.001, 0.0008]</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.9977, 0.0015, 0.0008]</td>\n",
       "      <td>{'enak': 'joli', 'nih': 'ici', 'soekarno': 'So...</td>\n",
       "      <td>2.5572</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>883</th>\n",
       "      <td>saya suka ur pizza dan calzone . karakter si r...</td>\n",
       "      <td>0</td>\n",
       "      <td>saya aimer tu pizza dan Calzone karakter si pa...</td>\n",
       "      <td>0.815185</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.9986, 0.0007, 0.0006]</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.9968, 0.0017, 0.0016]</td>\n",
       "      <td>{'banget': 'très', 'calzone': 'Calzone', 'suka...</td>\n",
       "      <td>4.8165</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>690</th>\n",
       "      <td>iya pak untuj transfer data ke komputer</td>\n",
       "      <td>1</td>\n",
       "      <td>oui pak pour transférer data ke komputer</td>\n",
       "      <td>0.759898</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.0016, 0.9972, 0.0012]</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.0016, 0.9751, 0.0233]</td>\n",
       "      <td>{'untuj': 'pour', 'transfer': 'transférer', 'i...</td>\n",
       "      <td>1.9375</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>ini adalaha salah satu tempat makan yang wajib...</td>\n",
       "      <td>0</td>\n",
       "      <td>ini est un salah satu tempat manger yang doit ...</td>\n",
       "      <td>0.891654</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.9983, 0.001, 0.0007]</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.9972, 0.0015, 0.0013]</td>\n",
       "      <td>{'enak': 'joli', 'adalaha': 'est un', 'restour...</td>\n",
       "      <td>6.7562</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>408</th>\n",
       "      <td>saya memesan iga bakar , setelah datang ternya...</td>\n",
       "      <td>2</td>\n",
       "      <td>saya memesan iga brûler setelah datang ternyat...</td>\n",
       "      <td>0.801182</td>\n",
       "      <td>2</td>\n",
       "      <td>[0.003, 0.0011, 0.9958]</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.0582, 0.5116, 0.4302]</td>\n",
       "      <td>{'mengecewakan': 'décevant', 'sungguh': 'série...</td>\n",
       "      <td>3.2675</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1132</th>\n",
       "      <td>kami mengunjungi tempat ini karena lokasi nya ...</td>\n",
       "      <td>0</td>\n",
       "      <td>kami visiter tempat ini karena lokasi le sien ...</td>\n",
       "      <td>0.920251</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.9983, 0.0011, 0.0007]</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.9959, 0.0023, 0.0018]</td>\n",
       "      <td>{'mahal': 'chere', 'fi': 'Fi', 'wi': 'Wi', 'ba...</td>\n",
       "      <td>6.5424</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>654</th>\n",
       "      <td>di sini saya suka lontong laksa dan lontong op...</td>\n",
       "      <td>0</td>\n",
       "      <td>di sini saya aimer gâteau de riz laksa dan gât...</td>\n",
       "      <td>0.772177</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.9985, 0.001, 0.0005]</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.9954, 0.0034, 0.0012]</td>\n",
       "      <td>{'suka': 'aimer', 'kroket': 'croquette', 'top'...</td>\n",
       "      <td>7.6449</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>the harvest ini setahu saya sudah ada beberapa...</td>\n",
       "      <td>0</td>\n",
       "      <td>la récolte ini Pour autant que saya sudah ada ...</td>\n",
       "      <td>0.802164</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.9969, 0.0009, 0.0021]</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.9885, 0.0042, 0.0074]</td>\n",
       "      <td>{'dicoba': 'essayer', 'harvest': 'récolte', 't...</td>\n",
       "      <td>7.0313</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>333</th>\n",
       "      <td>makan malam kali ini masih di sekitar di jalan...</td>\n",
       "      <td>0</td>\n",
       "      <td>manger malam temps ini masih di sekitar di jal...</td>\n",
       "      <td>0.825202</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.9984, 0.0007, 0.0008]</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.9965, 0.0014, 0.0021]</td>\n",
       "      <td>{'garing': 'croustillant', 'setiabudhi': 'Seti...</td>\n",
       "      <td>5.1676</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  sentiment  \\\n",
       "131   saya jadi tidak simpati lagi sama nikita mirza...          2   \n",
       "914   cocok buat makan buat yang punya teman banyak ...          0   \n",
       "883   saya suka ur pizza dan calzone . karakter si r...          0   \n",
       "690             iya pak untuj transfer data ke komputer          1   \n",
       "83    ini adalaha salah satu tempat makan yang wajib...          0   \n",
       "408   saya memesan iga bakar , setelah datang ternya...          2   \n",
       "1132  kami mengunjungi tempat ini karena lokasi nya ...          0   \n",
       "654   di sini saya suka lontong laksa dan lontong op...          0   \n",
       "565   the harvest ini setahu saya sudah ada beberapa...          0   \n",
       "333   makan malam kali ini masih di sekitar di jalan...          0   \n",
       "\n",
       "                                         perturbed_text  \\\n",
       "131   saya jadi tidak sympathie lagi sama nikita mir...   \n",
       "914   cocok buat makan buat yang punya ami banyak ic...   \n",
       "883   saya aimer tu pizza dan Calzone karakter si pa...   \n",
       "690            oui pak pour transférer data ke komputer   \n",
       "83    ini est un salah satu tempat manger yang doit ...   \n",
       "408   saya memesan iga brûler setelah datang ternyat...   \n",
       "1132  kami visiter tempat ini karena lokasi le sien ...   \n",
       "654   di sini saya aimer gâteau de riz laksa dan gât...   \n",
       "565   la récolte ini Pour autant que saya sudah ada ...   \n",
       "333   manger malam temps ini masih di sekitar di jal...   \n",
       "\n",
       "      perturbed_semantic_sim  pred_label                pred_proba  \\\n",
       "131                 0.863004           2  [0.0011, 0.0012, 0.9976]   \n",
       "914                 0.901243           0   [0.9982, 0.001, 0.0008]   \n",
       "883                 0.815185           0  [0.9986, 0.0007, 0.0006]   \n",
       "690                 0.759898           1  [0.0016, 0.9972, 0.0012]   \n",
       "83                  0.891654           0   [0.9983, 0.001, 0.0007]   \n",
       "408                 0.801182           2   [0.003, 0.0011, 0.9958]   \n",
       "1132                0.920251           0  [0.9983, 0.0011, 0.0007]   \n",
       "654                 0.772177           0   [0.9985, 0.001, 0.0005]   \n",
       "565                 0.802164           0  [0.9969, 0.0009, 0.0021]   \n",
       "333                 0.825202           0  [0.9984, 0.0007, 0.0008]   \n",
       "\n",
       "      perturbed_label           perturbed_proba  \\\n",
       "131                 2  [0.0412, 0.0089, 0.9499]   \n",
       "914                 0  [0.9977, 0.0015, 0.0008]   \n",
       "883                 0  [0.9968, 0.0017, 0.0016]   \n",
       "690                 1  [0.0016, 0.9751, 0.0233]   \n",
       "83                  0  [0.9972, 0.0015, 0.0013]   \n",
       "408                 1  [0.0582, 0.5116, 0.4302]   \n",
       "1132                0  [0.9959, 0.0023, 0.0018]   \n",
       "654                 0  [0.9954, 0.0034, 0.0012]   \n",
       "565                 0  [0.9885, 0.0042, 0.0074]   \n",
       "333                 0  [0.9965, 0.0014, 0.0021]   \n",
       "\n",
       "                                     translated_word(s)  running_time(s)  \\\n",
       "131   {'blokir': 'bloc', 'simpati': 'sympathie', 'me...           1.4578   \n",
       "914   {'enak': 'joli', 'nih': 'ici', 'soekarno': 'So...           2.5572   \n",
       "883   {'banget': 'très', 'calzone': 'Calzone', 'suka...           4.8165   \n",
       "690   {'untuj': 'pour', 'transfer': 'transférer', 'i...           1.9375   \n",
       "83    {'enak': 'joli', 'adalaha': 'est un', 'restour...           6.7562   \n",
       "408   {'mengecewakan': 'décevant', 'sungguh': 'série...           3.2675   \n",
       "1132  {'mahal': 'chere', 'fi': 'Fi', 'wi': 'Wi', 'ba...           6.5424   \n",
       "654   {'suka': 'aimer', 'kroket': 'croquette', 'top'...           7.6449   \n",
       "565   {'dicoba': 'essayer', 'harvest': 'récolte', 't...           7.0313   \n",
       "333   {'garing': 'croustillant', 'setiabudhi': 'Seti...           5.1676   \n",
       "\n",
       "      before_attack_acc  after_attack_acc  delta_acc  avg_semantic_sim  \\\n",
       "131                 1.0               0.9        0.1          0.835196   \n",
       "914                 NaN               NaN        NaN               NaN   \n",
       "883                 NaN               NaN        NaN               NaN   \n",
       "690                 NaN               NaN        NaN               NaN   \n",
       "83                  NaN               NaN        NaN               NaN   \n",
       "408                 NaN               NaN        NaN               NaN   \n",
       "1132                NaN               NaN        NaN               NaN   \n",
       "654                 NaN               NaN        NaN               NaN   \n",
       "565                 NaN               NaN        NaN               NaN   \n",
       "333                 NaN               NaN        NaN               NaN   \n",
       "\n",
       "      avg_running_time(s)  \n",
       "131               4.71789  \n",
       "914                   NaN  \n",
       "883                   NaN  \n",
       "690                   NaN  \n",
       "83                    NaN  \n",
       "408                   NaN  \n",
       "1132                  NaN  \n",
       "654                   NaN  \n",
       "565                   NaN  \n",
       "333                   NaN  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_dataset"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
