{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a666a356-cf28-4988-a99c-c5e8f8ee887d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LMOD_DIR=/usr/share/lmod/lmod/libexec/\n",
      "TMUX=/tmp/tmux-22086/default,1030980,0\n",
      "SSH_CLIENT=103.107.4.31 63325 22\n",
      "USER=m13518040\n",
      "LMOD_COLORIZE=yes\n",
      "MPLBACKEND=module://matplotlib_inline.backend_inline\n",
      "LMOD_PKG=/usr/share/lmod/lmod\n",
      "LD_LIBRARY_PATH=/usr/local/cuda/lib:/usr/local/cuda/lib\n",
      "HOME=/home/m13518040\n",
      "MOTD_SHOWN=pam\n",
      "OLDPWD=/raid/data/m13518040\n",
      "SSH_TTY=/dev/pts/2\n",
      "PAGER=cat\n",
      "TF_CPP_MIN_LOG_LEVEL=1\n",
      "LMOD_sys=Linux\n",
      "TF2_BEHAVIOR=1\n",
      "LOGNAME=m13518040\n",
      "TERM=xterm-color\n",
      "CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
      "PATH=/home/m13518040/.local/bin:/usr/local/cuda/bin:/opt/bin/:/usr/local/cuda/bin:/home/m13518040/.local/bin:/usr/local/cuda/bin:/opt/bin/:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin\n",
      "LMOD_FULL_SETTARG_SUPPORT=no\n",
      "LMOD_PREPEND_BLOCK=normal\n",
      "KMP_DUPLICATE_LIB_OK=True\n",
      "KMP_INIT_AT_FORK=FALSE\n",
      "LANG=en_US.UTF-8\n",
      "MODULEPATH_ROOT=/sw/modules\n",
      "SHELL=/bin/sh\n",
      "LMOD_CMD=/usr/share/lmod/lmod/libexec/lmod\n",
      "BASH_ENV=/usr/share/lmod/lmod/init/bash\n",
      "GIT_PAGER=cat\n",
      "PWD=/raid/data/m13518040/tugas-akhir-repository\n",
      "CLICOLOR=1\n",
      "SSH_CONNECTION=103.107.4.31 63325 167.205.35.247 22\n",
      "XDG_DATA_DIRS=/usr/local/share:/usr/share:/var/lib/snapd/desktop\n",
      "JPY_PARENT_PID=1034665\n",
      "PYDEVD_USE_FRAME_EVAL=NO\n",
      "LMOD_arch=x86_64\n",
      "MANPATH=/usr/share/lmod/lmod/share/man::\n",
      "MODULEPATH=/sw/modules/all\n",
      "TMUX_PANE=%0\n",
      "LMOD_SETTARG_CMD=:\n",
      "MODULESHOME=/usr/share/lmod/lmod\n",
      "LMOD_DIR=/usr/share/lmod/lmod/libexec/\n",
      "TMUX=/tmp/tmux-22086/default,1030980,0\n",
      "SSH_CLIENT=103.107.4.31 63325 22\n",
      "USER=m13518040\n",
      "LMOD_COLORIZE=yes\n",
      "MPLBACKEND=module://matplotlib_inline.backend_inline\n",
      "LMOD_PKG=/usr/share/lmod/lmod\n",
      "LD_LIBRARY_PATH=/usr/local/cuda/lib:/usr/local/cuda/lib\n",
      "HOME=/home/m13518040\n",
      "MOTD_SHOWN=pam\n",
      "OLDPWD=/raid/data/m13518040\n",
      "SSH_TTY=/dev/pts/2\n",
      "PAGER=cat\n",
      "TF_CPP_MIN_LOG_LEVEL=1\n",
      "LMOD_sys=Linux\n",
      "TF2_BEHAVIOR=1\n",
      "LOGNAME=m13518040\n",
      "TERM=xterm-color\n",
      "CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
      "PATH=/home/m13518040/.local/bin:/usr/local/cuda/bin:/opt/bin/:/usr/local/cuda/bin:/home/m13518040/.local/bin:/usr/local/cuda/bin:/opt/bin/:/usr/local/cuda/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin\n",
      "LMOD_FULL_SETTARG_SUPPORT=no\n",
      "LMOD_PREPEND_BLOCK=normal\n",
      "KMP_DUPLICATE_LIB_OK=True\n",
      "KMP_INIT_AT_FORK=FALSE\n",
      "LANG=en_US.UTF-8\n",
      "MODULEPATH_ROOT=/sw/modules\n",
      "SHELL=/bin/sh\n",
      "LMOD_CMD=/usr/share/lmod/lmod/libexec/lmod\n",
      "BASH_ENV=/usr/share/lmod/lmod/init/bash\n",
      "GIT_PAGER=cat\n",
      "PWD=/raid/data/m13518040/tugas-akhir-repository\n",
      "CLICOLOR=1\n",
      "SSH_CONNECTION=103.107.4.31 63325 167.205.35.247 22\n",
      "XDG_DATA_DIRS=/usr/local/share:/usr/share:/var/lib/snapd/desktop\n",
      "JPY_PARENT_PID=1034665\n",
      "PYDEVD_USE_FRAME_EVAL=NO\n",
      "LMOD_arch=x86_64\n",
      "MANPATH=/usr/share/lmod/lmod/share/man::\n",
      "MODULEPATH=/sw/modules/all\n",
      "TMUX_PANE=%0\n",
      "LMOD_SETTARG_CMD=:\n",
      "MODULESHOME=/usr/share/lmod/lmod\n",
      "CUDA_VISIBLE_DEVICES=4\n"
     ]
    }
   ],
   "source": [
    "# !export LD_LIBRARY_PATH=$LD_LIBRARY_PATH:/usr/local/cuda/lib64\n",
    "!env CUDA_DEVICE_ORDER=PCI_BUS_ID\n",
    "!env CUDA_VISIBLE_DEVICES=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d8a28c34-c97c-4875-b788-deea22e2fc49",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 40 workers.\n",
      "INFO: Pandarallel will use Memory file system to transfer data between the main process and workers.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/m13518040/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /home/m13518040/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package omw to /home/m13518040/nltk_data...\n",
      "[nltk_data]   Package omw is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "import gc\n",
    "import swifter\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "import time\n",
    "\n",
    "gc.collect()\n",
    "# os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"4,5\"  \n",
    "\n",
    "import random\n",
    "import numpy as np\n",
    "# import jax.numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('omw')\n",
    "\n",
    "stop_words_set = []\n",
    "for w in stopwords.words('indonesian'):\n",
    "    stop_words_set.append(w)\n",
    "\n",
    "import math\n",
    "import re\n",
    "import copy\n",
    "\n",
    "from operator import itemgetter\n",
    "from deep_translator import GoogleTranslator\n",
    "\n",
    "from utils.utils_forward_fn import forward_sequence_classification\n",
    "from utils.utils_init_dataset import set_seed, load_dataset_loader\n",
    "from utils.utils_semantic_use import USE\n",
    "from utils.utils_data_utils import DocumentSentimentDataset, DocumentSentimentDataLoader, EmotionDetectionDataset, EmotionDetectionDataLoader\n",
    "from utils.utils_metrics import document_sentiment_metrics_fn\n",
    "from utils.utils_init_model import text_logit, fine_tuning_model, eval_model, init_model, logit_prob, load_word_index\n",
    "from utils.get_args import get_args\n",
    "\n",
    "# debugger\n",
    "from icecream import ic\n",
    "\n",
    "# !pip install pandarallel\n",
    "from pandarallel import pandarallel\n",
    "pandarallel.initialize()\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "tqdm.pandas()\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cuda:3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "836e07b9-a236-4c59-896c-ea20950129c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \"xlmr-sentiment-codemixing-fr-adv-0.8\"\n",
    "model_target=\"XLM-R\"\n",
    "downstream_task=\"sentiment\"\n",
    "attack_strategy=\"adversarial\"\n",
    "# finetune_epoch=1\n",
    "num_sample=50\n",
    "# exp_name=\n",
    "perturbation_technique=\"codemixing\"\n",
    "perturb_ratio=0.8\n",
    "perturb_lang=\"fr\"\n",
    "seed=26092020\n",
    "dataset=\"valid\"\n",
    "\n",
    "set_seed(seed)\n",
    "use = USE()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "84b5a7b6-6ab2-49c4-a665-bb520a566f55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5b0eca17cd23432d94eb52023ff1d977",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      index  label\n",
      "0         0      2\n",
      "1         1      2\n",
      "2         2      0\n",
      "3         3      0\n",
      "4         4      2\n",
      "...     ...    ...\n",
      "1255   1255      2\n",
      "1256   1256      2\n",
      "1257   1257      2\n",
      "1258   1258      2\n",
      "1259   1259      0\n",
      "\n",
      "[1260 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "tokenizer, config, finetuned_model = init_model(model_target, downstream_task, seed)\n",
    "w2i, i2w = load_word_index(downstream_task)\n",
    "\n",
    "train_dataset, train_loader, train_path = load_dataset_loader(downstream_task, 'train', tokenizer)\n",
    "valid_dataset, valid_loader, valid_path = load_dataset_loader(downstream_task, 'valid', tokenizer)\n",
    "test_dataset, test_loader, test_path = load_dataset_loader(downstream_task, 'test', tokenizer)\n",
    "\n",
    "finetuned_model.to(device)\n",
    "# finetuned_model = fine_tuning_model(model, i2w, train_loader, valid_loader, finetune_epoch)\n",
    "\n",
    "if dataset == \"valid\":\n",
    "    exp_dataset = valid_dataset.load_dataset(valid_path)\n",
    "elif dataset == \"train\":\n",
    "    exp_dataset = train_dataset.load_dataset(train_path)\n",
    "# exp_dataset = dd.from_pandas(exp_dataset, npartitions=10)\n",
    "# exp_dataset = te.DataFrame.from_pandas(exp_dataset)\n",
    "# text,label = None,None\n",
    "\n",
    "finetuned_model.eval()\n",
    "\n",
    "torch.set_grad_enabled(False)\n",
    "\n",
    "LABEL2INDEX = {'positive': 0, 'neutral': 1, 'negative': 2}\n",
    "total_loss, total_correct, total_labels = 0, 0, 0\n",
    "list_hyp, list_label = [], []\n",
    "\n",
    "pbar = tqdm(valid_loader, leave=True, total=len(valid_loader))\n",
    "for i, batch_data in enumerate(pbar):\n",
    "    # ic(batch_data)\n",
    "    _, batch_hyp, _ = forward_sequence_classification(finetuned_model, batch_data[:-1], i2w=i2w, device='cuda')\n",
    "    list_hyp += batch_hyp\n",
    "    \n",
    "# Save prediction\n",
    "df = pd.DataFrame({'label':list_hyp}).reset_index()\n",
    "df['label'] = df['label'].apply(lambda sen: LABEL2INDEX[sen])\n",
    "# df.to_csv('pred.txt', index=False)\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b74da391-2c56-433a-96b3-d8a71095922f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['xlmr', 'sentiment', 'codemixing', 'fr', 'adv', '0.8']\n"
     ]
    }
   ],
   "source": [
    "exp_name = \"xlmr-sentiment-codemixing-fr-adv-0.8\"\n",
    "# exp_name = \"mbert-emotion-sr-adv-0.8-train\"\n",
    "names = exp_name.split(\"-\")\n",
    "\n",
    "print(exp_name.split(\"-\"))\n",
    "\n",
    "model_tgt = names[0]\n",
    "downstream_task = names[1]\n",
    "seed = 26092020"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e4387054-7f09-4d66-bdf5-f3f4addb856b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>perturbed_text</th>\n",
       "      <th>perturbed_semantic_sim</th>\n",
       "      <th>pred_label</th>\n",
       "      <th>pred_proba</th>\n",
       "      <th>perturbed_label</th>\n",
       "      <th>perturbed_proba</th>\n",
       "      <th>translated_word(s)</th>\n",
       "      <th>adv_pred</th>\n",
       "      <th>running_time(s)</th>\n",
       "      <th>before_attack_acc</th>\n",
       "      <th>after_attack_acc</th>\n",
       "      <th>avg_semantic_sim</th>\n",
       "      <th>avg_running_time(s)</th>\n",
       "      <th>adv_training</th>\n",
       "      <th>delta_acc</th>\n",
       "      <th>delta_adv</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>meski masa kampanye sudah selesai , bukan berati habis pula upaya mengerek tingkat kedipilihan elektabilitas .</td>\n",
       "      <td>1</td>\n",
       "      <td>meski masa kampanye sudah selesai , bukan berati habis pula upaya mengerek tingkat kedipilihan elektabilitas .</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2</td>\n",
       "      <td>[0.0343 0.3033 0.6625]</td>\n",
       "      <td>2</td>\n",
       "      <td>[0.0343 0.3033 0.6625]</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.930159</td>\n",
       "      <td>0.876984</td>\n",
       "      <td>0.791034</td>\n",
       "      <td>13.911119</td>\n",
       "      <td>0.876984</td>\n",
       "      <td>0.053175</td>\n",
       "      <td>0.053175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tidak enak</td>\n",
       "      <td>2</td>\n",
       "      <td>tidak agréable</td>\n",
       "      <td>0.711760</td>\n",
       "      <td>2</td>\n",
       "      <td>[0.0071 0.0017 0.9912]</td>\n",
       "      <td>2</td>\n",
       "      <td>[0.0219 0.0025 0.9756]</td>\n",
       "      <td>{'enak': 'agréable'}</td>\n",
       "      <td>2</td>\n",
       "      <td>4.36</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>restoran ini menawarkan makanan sunda . kami memesan ayam goreng , kangkung , sayur asam , ikan gurame goreng , ikan bakar , nasi goreng , karedok , tahu tempe , nasi putih , nasi merah etc minuman yang mereka tawarkan juga cukup variatif . rasa makanan enak dan harga murah . kami 9 dewasa dan 5 anak kecil , hanya menghabiskan 800,000</td>\n",
       "      <td>0</td>\n",
       "      <td>restaurant ini offrir aliments Sonde kami commande poulet frire chou frisé sayur asam poisson gurame frire poisson bakar riz frire karedok tahu tempeh riz blanche riz rouge etc boisson yang mereka offrir juga cukup variante rasa aliments agréable dan le prix peu coûteux kami 9 mature dan 5 enfant kecil hanya épuiser</td>\n",
       "      <td>0.588892</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.982  0.0041 0.0138]</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.965  0.0153 0.0197]</td>\n",
       "      <td>{'variatif': 'variante', 'harga': 'le prix', 'enak': 'agréable', 'makanan': 'aliments', 'merah': 'rouge', 'murah': 'peu coûteux', 'etc': 'etc', 'minuman': 'boisson', 'goreng': 'frire', 'tempe': 'tempeh', 'nasi': 'riz', 'restoran': 'restaurant', 'ikan': 'poisson', 'memesan': 'commande', 'anak': 'enfant', 'ayam': 'poulet', 'putih': 'blanche', 'tawarkan': 'offrir', 'menghabiskan': 'épuiser', 'menawarkan': 'offrir', 'sunda': 'Sonde', '5': '5', 'dewasa': 'mature', 'kangkung': 'chou frisé'}</td>\n",
       "      <td>0</td>\n",
       "      <td>13.16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lokasi di alun alun masakan padang ini cukup terkenal dengan kepala ikan kakap gule , biasa saya pesan nasi bungkus padang berisikan rendang , ayam pop dan perkedel . porsi banyak dan mengenyangkan</td>\n",
       "      <td>0</td>\n",
       "      <td>lokasi di carré carré cuisiner champ ini cukup célèbre dengan kepala poisson vivaneau gule biasa saya un message riz envelopper champ berisikan rendu poulet pop dan Gâteaux portion banyak dan remplissage</td>\n",
       "      <td>0.646173</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.9979 0.001  0.0011]</td>\n",
       "      <td>0</td>\n",
       "      <td>[0.9468 0.0361 0.0171]</td>\n",
       "      <td>{'mengenyangkan': 'remplissage', 'perkedel': 'Gâteaux', 'porsi': 'portion', 'pesan': 'un message', 'rendang': 'rendu', 'ayam': 'poulet', 'bungkus': 'envelopper', 'nasi': 'riz', 'pop': 'pop', 'padang': 'champ', 'terkenal': 'célèbre', 'alun': 'carré', 'ikan': 'poisson', 'kakap': 'vivaneau', 'masakan': 'cuisiner'}</td>\n",
       "      <td>0</td>\n",
       "      <td>9.23</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>betapa bejad kader gerindra yang anggota dprd mencabuli anak smp , rakyat harus cerdas partai mana yang harus di tengelamkan di 2019</td>\n",
       "      <td>2</td>\n",
       "      <td>comment dépravé kader gerindra yang membre DPRD agressé enfant lycée gens harus intelligent fête mana yang harus di noyer di 2019</td>\n",
       "      <td>0.686113</td>\n",
       "      <td>2</td>\n",
       "      <td>[0.0044 0.0131 0.9825]</td>\n",
       "      <td>1</td>\n",
       "      <td>[0.0135 0.7937 0.1929]</td>\n",
       "      <td>{'tengelamkan': 'noyer', 'mencabuli': 'agressé', 'cerdas': 'intelligent', 'betapa': 'comment', 'anak': 'enfant', 'partai': 'fête', 'rakyat': 'gens', 'anggota': 'membre', 'smp': 'lycée', 'bejad': 'dépravé', 'dprd': 'DPRD'}</td>\n",
       "      <td>2</td>\n",
       "      <td>8.07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                               text  \\\n",
       "0                                                                                                                                                                                                                                    meski masa kampanye sudah selesai , bukan berati habis pula upaya mengerek tingkat kedipilihan elektabilitas .   \n",
       "1                                                                                                                                                                                                                                                                                                                                        tidak enak   \n",
       "2  restoran ini menawarkan makanan sunda . kami memesan ayam goreng , kangkung , sayur asam , ikan gurame goreng , ikan bakar , nasi goreng , karedok , tahu tempe , nasi putih , nasi merah etc minuman yang mereka tawarkan juga cukup variatif . rasa makanan enak dan harga murah . kami 9 dewasa dan 5 anak kecil , hanya menghabiskan 800,000   \n",
       "3                                                                                                                                             lokasi di alun alun masakan padang ini cukup terkenal dengan kepala ikan kakap gule , biasa saya pesan nasi bungkus padang berisikan rendang , ayam pop dan perkedel . porsi banyak dan mengenyangkan   \n",
       "4                                                                                                                                                                                                              betapa bejad kader gerindra yang anggota dprd mencabuli anak smp , rakyat harus cerdas partai mana yang harus di tengelamkan di 2019   \n",
       "\n",
       "   sentiment  \\\n",
       "0          1   \n",
       "1          2   \n",
       "2          0   \n",
       "3          0   \n",
       "4          2   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                  perturbed_text  \\\n",
       "0                                                                                                                                                                                                                 meski masa kampanye sudah selesai , bukan berati habis pula upaya mengerek tingkat kedipilihan elektabilitas .   \n",
       "1                                                                                                                                                                                                                                                                                                                 tidak agréable   \n",
       "2  restaurant ini offrir aliments Sonde kami commande poulet frire chou frisé sayur asam poisson gurame frire poisson bakar riz frire karedok tahu tempeh riz blanche riz rouge etc boisson yang mereka offrir juga cukup variante rasa aliments agréable dan le prix peu coûteux kami 9 mature dan 5 enfant kecil hanya épuiser   \n",
       "3                                                                                                                    lokasi di carré carré cuisiner champ ini cukup célèbre dengan kepala poisson vivaneau gule biasa saya un message riz envelopper champ berisikan rendu poulet pop dan Gâteaux portion banyak dan remplissage   \n",
       "4                                                                                                                                                                                              comment dépravé kader gerindra yang membre DPRD agressé enfant lycée gens harus intelligent fête mana yang harus di noyer di 2019   \n",
       "\n",
       "   perturbed_semantic_sim  pred_label              pred_proba  \\\n",
       "0                1.000000           2  [0.0343 0.3033 0.6625]   \n",
       "1                0.711760           2  [0.0071 0.0017 0.9912]   \n",
       "2                0.588892           0  [0.982  0.0041 0.0138]   \n",
       "3                0.646173           0  [0.9979 0.001  0.0011]   \n",
       "4                0.686113           2  [0.0044 0.0131 0.9825]   \n",
       "\n",
       "   perturbed_label         perturbed_proba  \\\n",
       "0                2  [0.0343 0.3033 0.6625]   \n",
       "1                2  [0.0219 0.0025 0.9756]   \n",
       "2                0  [0.965  0.0153 0.0197]   \n",
       "3                0  [0.9468 0.0361 0.0171]   \n",
       "4                1  [0.0135 0.7937 0.1929]   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          translated_word(s)  \\\n",
       "0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                        NaN   \n",
       "1                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       {'enak': 'agréable'}   \n",
       "2  {'variatif': 'variante', 'harga': 'le prix', 'enak': 'agréable', 'makanan': 'aliments', 'merah': 'rouge', 'murah': 'peu coûteux', 'etc': 'etc', 'minuman': 'boisson', 'goreng': 'frire', 'tempe': 'tempeh', 'nasi': 'riz', 'restoran': 'restaurant', 'ikan': 'poisson', 'memesan': 'commande', 'anak': 'enfant', 'ayam': 'poulet', 'putih': 'blanche', 'tawarkan': 'offrir', 'menghabiskan': 'épuiser', 'menawarkan': 'offrir', 'sunda': 'Sonde', '5': '5', 'dewasa': 'mature', 'kangkung': 'chou frisé'}   \n",
       "3                                                                                                                                                                                   {'mengenyangkan': 'remplissage', 'perkedel': 'Gâteaux', 'porsi': 'portion', 'pesan': 'un message', 'rendang': 'rendu', 'ayam': 'poulet', 'bungkus': 'envelopper', 'nasi': 'riz', 'pop': 'pop', 'padang': 'champ', 'terkenal': 'célèbre', 'alun': 'carré', 'ikan': 'poisson', 'kakap': 'vivaneau', 'masakan': 'cuisiner'}   \n",
       "4                                                                                                                                                                                                                                                                              {'tengelamkan': 'noyer', 'mencabuli': 'agressé', 'cerdas': 'intelligent', 'betapa': 'comment', 'anak': 'enfant', 'partai': 'fête', 'rakyat': 'gens', 'anggota': 'membre', 'smp': 'lycée', 'bejad': 'dépravé', 'dprd': 'DPRD'}   \n",
       "\n",
       "   adv_pred  running_time(s)  before_attack_acc  after_attack_acc  \\\n",
       "0         2             0.05           0.930159          0.876984   \n",
       "1         2             4.36                NaN               NaN   \n",
       "2         0            13.16                NaN               NaN   \n",
       "3         0             9.23                NaN               NaN   \n",
       "4         2             8.07                NaN               NaN   \n",
       "\n",
       "   avg_semantic_sim  avg_running_time(s)  adv_training  delta_acc  delta_adv  \n",
       "0          0.791034            13.911119      0.876984   0.053175   0.053175  \n",
       "1               NaN                  NaN           NaN        NaN        NaN  \n",
       "2               NaN                  NaN           NaN        NaN        NaN  \n",
       "3               NaN                  NaN           NaN        NaN        NaN  \n",
       "4               NaN                  NaN           NaN        NaN        NaN  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_df = pd.read_csv(os.getcwd() + r'/result/seed'+str(seed)+\"/valid/\"+exp_name+\"-valid\"+\".csv\")\n",
    "\n",
    "# valid_df[\"adv_pred\"] = df[\"label\"]\n",
    "valid_df.insert(loc=9, column='adv_pred', value=df[\"label\"].values)\n",
    "adv_training = accuracy_score(valid_df[\"sentiment\"], valid_df['perturbed_label'])\n",
    "delta_acc = valid_df.before_attack_acc.values[0] - valid_df.after_attack_acc.values[0]\n",
    "delta_adv = valid_df.before_attack_acc.values[0] - adv_training \n",
    "\n",
    "\n",
    "valid_df.loc[valid_df.index[0], 'adv_training'] = adv_training\n",
    "valid_df.loc[valid_df.index[0], 'delta_acc'] = delta_acc\n",
    "valid_df.loc[valid_df.index[0], 'delta_adv'] = delta_adv\n",
    "\n",
    "valid_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f5cbf683-6217-4abd-b11f-27aed9f889ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9301587301587302"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_df.before_attack_acc.values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf2ce37-74ad-428a-afa6-3584ebf8292b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65714cd5-7b2b-4bda-8b5a-f4c06b6f6e2f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83b7801a-ec2d-49ee-9865-a0ecc345a854",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ce752fbe-45b2-4505-ba52-cfa966e4f9cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| trainpath: '/raid/data/m13518040/tugas-akhir-repository/result/seed26092020/train/xlmr-sentiment-codemixing-fr-adv-0.8-train.csv'\n",
      "ic| validpath: '/raid/data/m13518040/tugas-akhir-repository/result/seed26092020/valid/xlmr-sentiment-codemixing-fr-adv-0.8-valid.csv'\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "load_dataset_loader() takes 3 positional arguments but 4 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [17]\u001b[0m, in \u001b[0;36m<cell line: 14>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m ic(trainpath)\n\u001b[1;32m     12\u001b[0m ic(validpath)\n\u001b[0;32m---> 14\u001b[0m train_dataset, train_loader, _ \u001b[38;5;241m=\u001b[39m \u001b[43mload_dataset_loader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdownstream_task\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrainpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m valid_dataset, valid_loader, _ \u001b[38;5;241m=\u001b[39m load_dataset_loader(downstream_task, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mvalid\u001b[39m\u001b[38;5;124m'\u001b[39m, tokenizer, validpath)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# test_dataset, test_loader, test_path = load_dataset_loader(downstream_task, 'test', tokenizer)\u001b[39;00m\n",
      "\u001b[0;31mTypeError\u001b[0m: load_dataset_loader() takes 3 positional arguments but 4 were given"
     ]
    }
   ],
   "source": [
    "set_seed(seed)\n",
    "# use = USE()\n",
    "\n",
    "#     baca hasil perturb -> finetuning pake perturbed training -> predict data valid\n",
    "tokenizer, config, model = init_model(model_target, downstream_task, seed)\n",
    "w2i, i2w = load_word_index(downstream_task)\n",
    "\n",
    "trainpath = os.getcwd() + r'/result/seed'+str(seed)+\"/train/\"+exp_name+\"-train\"+\".csv\"\n",
    "validpath = os.getcwd() + r'/result/seed'+str(seed)+\"/valid/\"+exp_name+\"-valid\"+\".csv\"\n",
    "\n",
    "ic(trainpath)\n",
    "ic(validpath)\n",
    "\n",
    "train_dataset, train_loader, _ = load_dataset_loader(downstream_task, 'train', tokenizer, trainpath)\n",
    "valid_dataset, valid_loader, _ = load_dataset_loader(downstream_task, 'valid', tokenizer, validpath)\n",
    "# test_dataset, test_loader, test_path = load_dataset_loader(downstream_task, 'test', tokenizer)\n",
    "\n",
    "\n",
    "\n",
    "if \"sentiment\" in trainpath: \n",
    "    finetuned_model = fine_tuning_model(model, i2w, train_loader, valid_loader, epochs=5)\n",
    "else: \n",
    "    finetuned_model = fine_tuning_model(model, i2w, train_loader, valid_loader, epochs=10)\n",
    "\n",
    "# valid_df = pd.read_csv(os.getcwd() + r'/result/seed'+str(seed)+\"/valid/\"+exp_name+\"-valid\"+\".csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1c4fe57-5a3b-4afc-bde4-1a81e607f428",
   "metadata": {},
   "outputs": [],
   "source": [
    "finetuned_model.eval()\n",
    "\n",
    "torch.set_grad_enabled(False)\n",
    "\n",
    "total_loss, total_correct, total_labels = 0, 0, 0\n",
    "list_hyp, list_label = [], []\n",
    "\n",
    "pbar = tqdm(valid_loader, leave=True, total=len(test_loader))\n",
    "for i, batch_data in enumerate(pbar):\n",
    "    # ic(batch_data)\n",
    "    _, batch_hyp, _ = forward_sequence_classification(finetuned_model, batch_data[:-1], i2w=i2w, device='cuda')\n",
    "    list_hyp += batch_hyp\n",
    "\n",
    "# Save prediction\n",
    "df = pd.DataFrame({'label':list_hyp}).reset_index()\n",
    "# df.to_csv('pred.txt', index=False)\n",
    "\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfc01f6a-e4a5-4a41-9ef5-81bac3f82b3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f1f60b-0752-4aaa-8cab-4685e7a35e06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0dd8c72-3016-4282-b3b1-67a11c7ede70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f56ced3b-403c-488c-b085-28baacda82a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "myenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
