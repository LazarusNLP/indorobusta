{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "4941366e-c680-4626-bdfd-fe293ac4fb9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as axes\n",
    "import numpy as np\n",
    "from matplotlib.pyplot import figure\n",
    "import pandas as pd\n",
    "# import matplotlib.pyplot as plt\n",
    "# import matplotlib\n",
    "from matplotlib.pyplot import figure, xticks\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from deep_translator import GoogleTranslator\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "# plt.rcParams['axes.facecolor'] = 'white'\n",
    "pd.set_option('display.max_colwidth', None)\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4083ca53-b502-4bea-a994-e94562f7220a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xlmr-sentiment-codemixing-fr-adv-0.8-train\n"
     ]
    }
   ],
   "source": [
    "model_target = \"xlmr\"\n",
    "downstream_task = \"sentiment\"\n",
    "attack_strategy = \"codemixing\"\n",
    "perturbation_technique = \"adv\"\n",
    "perturb_ratio = 0.8\n",
    "dataset = \"train\"\n",
    "perturb_lang = \"fr\"\n",
    "seed = 26092020\n",
    "\n",
    "finetune_epoch = 0\n",
    "if downstream_task == \"sentiment\":\n",
    "    finetune_epoch = 5\n",
    "if downstream_task == \"emotion\":\n",
    "    finetune_epoch = 10\n",
    "\n",
    "exp_name = model_target+\"-\"+downstream_task+\"-\"+attack_strategy+\"-\"+perturb_lang+\"-adv\"+\"-\"+str(perturb_ratio)+\"-\"+dataset\n",
    "# exp_name = \"indobert-emotion-codemixing-en-adv-0.2-train\"\n",
    "print(exp_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c0a1bcee-635c-43b0-93ef-27e5beca4c0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>perturbed_text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>décrochage en bordure de route ini possédé oleh homme d'affaire usine tahu yang sudah douzaines tahun célèbre membuat tahu blanche di Bandung tahu qualité combiné compétence memasak combiné la créativité jadilah décrochage en bordure de route yang menyajikan menu utama fait à partir de tahu ditambah menu umum lain seperti ayam semuanya appétit Indonésie le prix cukup abordable jangan Mademoiselle tahu bletoka le sien tidak perdu dengan yang asli dari domaine</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mohon clerc droit dan k212 mmbri preuve faire la fête apa yang harus diwlh agar voix islam tidak</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lokasi stratégique di jalan Sumatra Bandung tempat le sien nyaman terutama sofa di étage 2 Paëlla le sien joli sangat en forme dimakan dengan boire Bière du froid apéritif le sien juga</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>comment bahagia le sien diri ini saat déballage emballer dan des biens le sien bon Positionner acheter lagi</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>duh jadi étudiant jangan fier dong amour carte Jaune segala étude dulu yang baik tidak usahlah politique nanti sudah Fini en train d'étudier le sien mau ikut politique juga tidak telat base étudiant</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10995</th>\n",
       "      <td>tidak déçu</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10996</th>\n",
       "      <td>enak rasa Cuisiner le sien apalagi Crabe yang agréable kita choisir Crabe le sien sendiri dan masih Frais selalu arrêtez-vous ke sini kalau setiap ke bandung</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10997</th>\n",
       "      <td>respect yang telah berkoalisi</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10998</th>\n",
       "      <td>Matin Matin di péage pasteur sudah congestionné critique Fabriquer jengkel saja ini</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10999</th>\n",
       "      <td>meskipun sering achats ke yoga di Riau jonction tapi baru pertama temps ini saya voir la vie alimentaire tempat le sien grande dan faire le ménage tidak taudis semacam aire de restauration lainnya dan choix aliments le sien banyak très dari yang traditionnel sampai aliments Ouest ataupun asian mau yang lourd sampai ke yang léger hampir semuanya ada tinggal sélectionner dan disesuaikan sama biaya makan le sien saja</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                       perturbed_text  \\\n",
       "0      décrochage en bordure de route ini possédé oleh homme d'affaire usine tahu yang sudah douzaines tahun célèbre membuat tahu blanche di Bandung tahu qualité combiné compétence memasak combiné la créativité jadilah décrochage en bordure de route yang menyajikan menu utama fait à partir de tahu ditambah menu umum lain seperti ayam semuanya appétit Indonésie le prix cukup abordable jangan Mademoiselle tahu bletoka le sien tidak perdu dengan yang asli dari domaine   \n",
       "1                                                                                                                                                                                                                                                                                                                                                                                    mohon clerc droit dan k212 mmbri preuve faire la fête apa yang harus diwlh agar voix islam tidak   \n",
       "2                                                                                                                                                                                                                                                                                            lokasi stratégique di jalan Sumatra Bandung tempat le sien nyaman terutama sofa di étage 2 Paëlla le sien joli sangat en forme dimakan dengan boire Bière du froid apéritif le sien juga   \n",
       "3                                                                                                                                                                                                                                                                                                                                                                         comment bahagia le sien diri ini saat déballage emballer dan des biens le sien bon Positionner acheter lagi   \n",
       "4                                                                                                                                                                                                                                                                              duh jadi étudiant jangan fier dong amour carte Jaune segala étude dulu yang baik tidak usahlah politique nanti sudah Fini en train d'étudier le sien mau ikut politique juga tidak telat base étudiant   \n",
       "...                                                                                                                                                                                                                                                                                                                                                                                                                                                                               ...   \n",
       "10995                                                                                                                                                                                                                                                                                                                                                                                                                                                                      tidak déçu   \n",
       "10996                                                                                                                                                                                                                                                                                                                   enak rasa Cuisiner le sien apalagi Crabe yang agréable kita choisir Crabe le sien sendiri dan masih Frais selalu arrêtez-vous ke sini kalau setiap ke bandung   \n",
       "10997                                                                                                                                                                                                                                                                                                                                                                                                                                                   respect yang telah berkoalisi   \n",
       "10998                                                                                                                                                                                                                                                                                                                                                                                             Matin Matin di péage pasteur sudah congestionné critique Fabriquer jengkel saja ini   \n",
       "10999                                               meskipun sering achats ke yoga di Riau jonction tapi baru pertama temps ini saya voir la vie alimentaire tempat le sien grande dan faire le ménage tidak taudis semacam aire de restauration lainnya dan choix aliments le sien banyak très dari yang traditionnel sampai aliments Ouest ataupun asian mau yang lourd sampai ke yang léger hampir semuanya ada tinggal sélectionner dan disesuaikan sama biaya makan le sien saja   \n",
       "\n",
       "       sentiment  \n",
       "0              0  \n",
       "1              1  \n",
       "2              0  \n",
       "3              0  \n",
       "4              2  \n",
       "...          ...  \n",
       "10995          0  \n",
       "10996          0  \n",
       "10997          1  \n",
       "10998          2  \n",
       "10999          0  \n",
       "\n",
       "[11000 rows x 2 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = os.getcwd() + r'/result/seed'+str(seed)+\"/\"+str(dataset)+\"/\"+str(exp_name)+\".csv\"\n",
    "df = pd.read_csv(path)\n",
    "df = df[[\"perturbed_text\", \"sentiment\"]]\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8f4e9e95-6bd3-4cc1-8662-9f2564928001",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "281\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "279"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from icecream import ic\n",
    "\n",
    "# dataset = \"valid\"\n",
    "# seed = 26092020\n",
    "seed = 24032022\n",
    "seed = 42\n",
    "# valid_df.to_csv(os.getcwd() + r'/adversarial-training/result/seed'+str(seed)+\"/\"+str(exp_name)+\".csv\", index=False)\n",
    "\n",
    "def get_intersect(seed):\n",
    "    path_train = str(os.getcwd()) + \"/result/seed\" + str(seed) + \"/\" + \"train\" + \"/\"\n",
    "    path_test = str(os.getcwd()) + \"/result/seed\" + str(seed) + \"/\" + \"test\" + \"/\"\n",
    "\n",
    "    dir_list_train = [f[:-10] for f in os.listdir(path_train)]\n",
    "    dir_list_test = [f[:-9] for f in os.listdir(path_test)]\n",
    "    \n",
    "    print(len(dir_list_test))\n",
    "    # print(len(dir_list_train))\n",
    "    # print(set(dir_list_valid) - set(dir_list_train))\n",
    "    return list(set(dir_list_train) & set(dir_list_test))\n",
    "\n",
    "intersect = get_intersect(seed)\n",
    "len(intersect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "71a930f6-980a-40da-9ebf-9cb113803c67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path_adv = os.getcwd() + r'/adversarial-training/result/seed'+str(seed)+\"/\"\n",
    "dir_list_adv = [f[:-4] for f in os.listdir(path_adv)]\n",
    "\n",
    "exp_name = \"mbert-emotion-sr-adv-0.8\"\n",
    "exp_name in intersect and exp_name not in dir_list_adv and 'ipynb' not in exp_name\n",
    "# if exp_name in intersect and exp_name not in dir_list_adv and 'ipynb' not in exp_name:\n",
    "#     print()\n",
    "dir_list_adv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add854e9-bfce-48e9-a3b0-afb8118f55ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_train = str(os.getcwd()) + \"/result/seed\" + str(seed) + \"/\" + \"train\" + \"/\"\n",
    "path_valid = str(os.getcwd()) + \"/result/seed\" + str(seed) + \"/\" + \"valid\" + \"/\"\n",
    "\n",
    "dir_list_train = [f[:-10] for f in os.listdir(path_train)]\n",
    "dir_list_valid = [f[:-10] for f in os.listdir(path_valid)]\n",
    "\n",
    "# dir_list_train\n",
    "# dir_list_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1dbc9550-2b22-4a19-ae3d-20c440cbe06d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_reader(path):\n",
    "    a_file = open(path, \"r\")\n",
    "\n",
    "    vocab = []\n",
    "    for line in a_file:\n",
    "        stripped_line = line.strip()\n",
    "        vocab.append(stripped_line)\n",
    "\n",
    "    a_file.close()\n",
    "    return list(set(vocab))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b2f39034-ff45-4030-b735-130f58301351",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "que\n",
      "5718\n"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "  \n",
    "# reading the data from the file\n",
    "with open('dict_fr.txt') as f:\n",
    "    data = f.read()\n",
    "      \n",
    "# reconstructing the data as a dictionary\n",
    "d = ast.literal_eval(data)\n",
    "print(d['kamu'])\n",
    "same_val = []\n",
    "for k in d.keys():\n",
    "    if k == d[k]:\n",
    "        # print(k, d[k])\n",
    "        same_val.append(k)\n",
    "\n",
    "print(len(same_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "26712731-33b2-4af5-970c-cfdd45a6e576",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_dict(filename):\n",
    "    with open(filename) as f:\n",
    "        data = f.read()\n",
    "      \n",
    "    # reconstructing the data as a dictionary\n",
    "    d = ast.literal_eval(data)\n",
    "    # print(type(d))\n",
    "    return d\n",
    "\n",
    "def translate_batch(wordlist,translator, online_trans):\n",
    "    translated = []\n",
    "    print(wordlist)\n",
    "    for w in wordlist:\n",
    "        # print(translator[w])\n",
    "        if w in translator.keys():\n",
    "            trans = translator[w]\n",
    "        else:\n",
    "            trans = online_trans.translate(w)\n",
    "        translated.append(trans)\n",
    "        \n",
    "    return translated\n",
    "\n",
    "def trans_dict_cache(wordlist, lang=None):\n",
    "    \n",
    "    translator = read_dict(os.getcwd() + r\"/dicts/new_dict_\"+lang+\".txt\")\n",
    "    online_trans = GoogleTranslator(source=\"id\", target=target_lang)\n",
    "    new_wp = []\n",
    "    for wp in wordlist:\n",
    "        if wp[1].isalpha():\n",
    "            new_wp.append(wp[1])\n",
    "    \n",
    "    if len(new_wp) == 1:\n",
    "        new_wp_trans = dict(zip(new_wp, translator[new_wp[0]]))\n",
    "    elif len(new_wp) == 0:\n",
    "        return ' '.join(words), {}\n",
    "        \n",
    "    new_wp_trans = dict(zip(new_wp, translate_batch(new_wp)))\n",
    "    \n",
    "    supported_langs = [\"su\", \"jw\", \"ms\", \"en\", \"fr\", \"it\"]\n",
    "    \n",
    "    if target_lang not in supported_langs:\n",
    "        raise ValueError('Language Unavailable')\n",
    "    \n",
    "    new_words = words.copy()\n",
    "    \n",
    "    if len(words_perturb) >= 1:\n",
    "        for perturb_word in new_wp_trans.keys():\n",
    "            new_words = [new_wp_trans[perturb_word] if word == perturb_word and word.isalpha() else word for word in new_words]\n",
    "\n",
    "    return ' '.join(new_words), new_wp_trans\n",
    "#     translated_wordlist = {}\n",
    "#     # ic(wordlist)\n",
    "#     supported_langs = [\"su\", \"jw\", \"ms\", \"en\", \"fr\", \"it\"]\n",
    "    \n",
    "#     if lang not in supported_langs:\n",
    "#         raise ValueError('Language Unavailable')\n",
    "    \n",
    "#     translator = read_dict(os.getcwd() + r\"/dicts/dict_\"+lang+\".txt\")\n",
    "#     online_trans = GoogleTranslator(source=\"id\", target=lang)\n",
    "#     # translator = GoogleTranslator(source=\"id\", target=lang)\n",
    "    \n",
    "#     alpha = []\n",
    "#     non_alpha = {}\n",
    "#     for word in wordlist:\n",
    "#         if word.isdigit():\n",
    "#             non_alpha[word] = word\n",
    "#         elif any(c.isalpha() for c in word):\n",
    "#             alpha.append(word)\n",
    "#         else:\n",
    "#             non_alpha[word] = word\n",
    "    \n",
    "#     # trans_alpha = translate_batch(alpha,translator)\n",
    "#     translated_alpha = dict(zip(alpha, translate_batch(alpha,translator,online_trans)))\n",
    "\n",
    "#     translated_wordlist = {**non_alpha, **translated_alpha}\n",
    "#     # if len(translated_wordlist)%10 == 0:\n",
    "#     return translated_wordlist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "55dec143-b770-4cb4-913b-d9a64457d81b",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'dict' object has no attribute 'translate_batch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [65]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrans_dict_cache\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mai\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msu\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [64]\u001b[0m, in \u001b[0;36mtrans_dict_cache\u001b[0;34m(wordlist, lang)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(new_wp) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m     35\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(words), {}\n\u001b[0;32m---> 37\u001b[0m new_wp_trans \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\u001b[38;5;28mzip\u001b[39m(new_wp, \u001b[43mtranslator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtranslate_batch\u001b[49m(new_wp)))\n\u001b[1;32m     39\u001b[0m supported_langs \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msu\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjw\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mms\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124men\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfr\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mit\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m target_lang \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m supported_langs:\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'dict' object has no attribute 'translate_batch'"
     ]
    }
   ],
   "source": [
    "trans_dict_cache(['ai'], 'su')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "b39aa6df-2a3a-41be-9072-f9c4b5d3e03e",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'semoga'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[0;32mIn [80]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m lang \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mjw\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      2\u001b[0m translator \u001b[38;5;241m=\u001b[39m read_dict(os\u001b[38;5;241m.\u001b[39mgetcwd() \u001b[38;5;241m+\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/dicts/dict_\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39mlang\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 3\u001b[0m \u001b[43mtranslator\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43msemoga\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'semoga'"
     ]
    }
   ],
   "source": [
    "lang = 'jw'\n",
    "translator = read_dict(os.getcwd() + r\"/dicts/dict_\"+lang+\".txt\")\n",
    "translator['semoga']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "89273da6-d205-49e8-b32f-b408b4a32b43",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'gitu' in translator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5cfd37ff-3612-40a9-a508-b33755097ac9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "seed = 26092020\n",
    "dataset = \"train\"\n",
    "exp_name = \"indobert-emotion-codemixing-su-adv-0.2-train\"\n",
    "\n",
    "path_to_res = os.getcwd() + r'/result/seed'+str(seed)+\"/\"+str(dataset)+\"/\"\n",
    "dir_list_res = os.listdir(path_to_res)\n",
    "dir_list_res\n",
    "\n",
    "exp_name+\".csv\" in dir_list_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "712fd48f-646e-4bf4-8af4-c9d6b82ef5a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_adv = os.getcwd() + r'/adversarial-training/result/seed'+str(seed)+\"/\"\n",
    "dir_list_adv = [f[:-4] for f in os.listdir(path_adv) if \"ipynb\" not in f]\n",
    "# dir_list_adv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "340b9d96-6e4d-42fe-8d30-3cd5c91f4ca4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Aing maung'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_ls = \"Aing...... maung!!!\"\n",
    "\n",
    "# text_ls = [word for word in text_ls if word.isalnum()]\n",
    "\n",
    "# text_ls\n",
    "\n",
    "# ''.join(filter(str.isalnum,text_ls))\n",
    "\n",
    "import re\n",
    "\n",
    "t = re.sub(r'[^A-Za-z0-9 ]+', '', text_ls)\n",
    "t\n",
    "#First parameter is the replacement, second parameter is your input string\n",
    "# regex.sub('', text_ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "dd64238c-1966-4ae3-a6fa-fca31fe08553",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'cinta'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[0;32mIn [37]\u001b[0m, in \u001b[0;36m<cell line: 14>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m target_lang \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mjw\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     13\u001b[0m translator \u001b[38;5;241m=\u001b[39m read_dict(os\u001b[38;5;241m.\u001b[39mgetcwd() \u001b[38;5;241m+\u001b[39m \u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/dicts/dict_\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m+\u001b[39mtarget_lang\u001b[38;5;241m+\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 14\u001b[0m \u001b[43mtranslator\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcinta\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'cinta'"
     ]
    }
   ],
   "source": [
    "import ast\n",
    "\n",
    "def read_dict(filename):\n",
    "    with open(filename) as f:\n",
    "        data = f.read()\n",
    "      \n",
    "    # reconstructing the data as a dictionary\n",
    "    d = ast.literal_eval(data)\n",
    "    # print(type(d))\n",
    "    return d\n",
    "\n",
    "target_lang = \"jw\"\n",
    "translator = read_dict(os.getcwd() + r\"/dicts/dict_\"+target_lang+\".txt\")\n",
    "translator['cinta']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b02f75d-ec8c-4148-a0d4-dfe52dd0f4fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_reader(path):\n",
    "    a_file = open(path, \"r\")\n",
    "\n",
    "    vocab = []\n",
    "    for line in a_file:\n",
    "        stripped_line = line.strip()\n",
    "        vocab.append(stripped_line)\n",
    "\n",
    "    a_file.close()\n",
    "    return list(set(vocab))\n",
    "\n",
    "allvocab = file_reader(os.getcwd() + r\"/dicts/allvocab.txt\")\n",
    "# allvocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "e49aff95-fa56-4287-957d-dbd805b3979c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "any(\"dimatikan\" in word for word in allvocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b35f73b6-c06a-4419-88bc-dbc103abb340",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "path1 = './dataset/smsa-document-sentiment/train_preprocess.csv'\n",
    "path2 = './result/seed42/train/indobert-sentiment-codemixing-en-adv-0.2-train.csv'\n",
    "\n",
    "df1 = pd.read_csv(path1)\n",
    "df2 = pd.read_csv(path2)[['perturbed_text', 'sentiment']]\n",
    "df2.columns = ['text', 'sentiment']\n",
    "\n",
    "dataset = pd.concat((df1, df2), axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c5fd13f3-c901-43c4-98c1-4eb47fa94a6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>warung ini dimiliki oleh pengusaha pabrik tahu...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mohon ulama lurus dan k212 mmbri hujjah partai...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lokasi strategis di jalan sumatera bandung . t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>betapa bahagia nya diri ini saat unboxing pake...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>duh . jadi mahasiswa jangan sombong dong . kas...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10995</th>\n",
       "      <td>tidak kecewa</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10996</th>\n",
       "      <td>nice rasa masakan nya apalagi kepiting yang me...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10997</th>\n",
       "      <td>hormati yang telah coalition</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10998</th>\n",
       "      <td>pagi pagi di tol pasteur sudah macet parah bik...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10999</th>\n",
       "      <td>meskipun sering belanja ke yogya di riau junct...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  sentiment\n",
       "0      warung ini dimiliki oleh pengusaha pabrik tahu...          0\n",
       "1      mohon ulama lurus dan k212 mmbri hujjah partai...          1\n",
       "2      lokasi strategis di jalan sumatera bandung . t...          0\n",
       "3      betapa bahagia nya diri ini saat unboxing pake...          0\n",
       "4      duh . jadi mahasiswa jangan sombong dong . kas...          2\n",
       "...                                                  ...        ...\n",
       "10995                                       tidak kecewa          0\n",
       "10996  nice rasa masakan nya apalagi kepiting yang me...          0\n",
       "10997                       hormati yang telah coalition          1\n",
       "10998  pagi pagi di tol pasteur sudah macet parah bik...          2\n",
       "10999  meskipun sering belanja ke yogya di riau junct...          0\n",
       "\n",
       "[22000 rows x 2 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "098563f3-62db-4cd7-91af-24ceadf8e048",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>warung ini dimiliki oleh pengusaha pabrik tahu...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>mohon ulama lurus dan k212 mmbri hujjah party ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>lokasi strategis di jalan sumatera bandung tem...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>betapa happy nya diri ini saat unboxing paket ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>duh jadi mahasiswa jangan sombong dong kasih k...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10995</th>\n",
       "      <td>tidak kecewa</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10996</th>\n",
       "      <td>nice rasa masakan nya apalagi kepiting yang me...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10997</th>\n",
       "      <td>hormati yang telah coalition</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10998</th>\n",
       "      <td>pagi pagi di tol pasteur sudah macet parah bik...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10999</th>\n",
       "      <td>meskipun sering belanja ke yogya di riau junct...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text  sentiment\n",
       "0      warung ini dimiliki oleh pengusaha pabrik tahu...          0\n",
       "1      mohon ulama lurus dan k212 mmbri hujjah party ...          1\n",
       "2      lokasi strategis di jalan sumatera bandung tem...          0\n",
       "3      betapa happy nya diri ini saat unboxing paket ...          0\n",
       "4      duh jadi mahasiswa jangan sombong dong kasih k...          2\n",
       "...                                                  ...        ...\n",
       "10995                                       tidak kecewa          0\n",
       "10996  nice rasa masakan nya apalagi kepiting yang me...          0\n",
       "10997                       hormati yang telah coalition          1\n",
       "10998  pagi pagi di tol pasteur sudah macet parah bik...          2\n",
       "10999  meskipun sering belanja ke yogya di riau junct...          0\n",
       "\n",
       "[11000 rows x 2 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "802a8b45-7c56-43aa-8d74-521813cd89c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>kemarin gue datang ke tempat makan baru yang a...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>kayak nya sih gue tidak akan mau balik lagi ke...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>kalau dipikir-pikir , sebenarnya tidak ada yan...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ini pertama kalinya gua ke bank buat ngurusin ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>waktu sampai dengan gue pernah disuruh ibu lat...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>kata nya tidur yang baik itu minimal enam jam ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>indonesia itu ada di benua asia .</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>salah satu kegemaran anak remaja indonesia sek...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>melihat warna hijau bisa bikin mata jadi lebih...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>bondan winarno yang suka bilang maknyus sekara...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                  text  sentiment\n",
       "0    kemarin gue datang ke tempat makan baru yang a...          1\n",
       "1    kayak nya sih gue tidak akan mau balik lagi ke...          1\n",
       "2    kalau dipikir-pikir , sebenarnya tidak ada yan...          1\n",
       "3    ini pertama kalinya gua ke bank buat ngurusin ...          1\n",
       "4    waktu sampai dengan gue pernah disuruh ibu lat...          1\n",
       "..                                                 ...        ...\n",
       "495  kata nya tidur yang baik itu minimal enam jam ...          1\n",
       "496                  indonesia itu ada di benua asia .          1\n",
       "497  salah satu kegemaran anak remaja indonesia sek...          1\n",
       "498  melihat warna hijau bisa bikin mata jadi lebih...          1\n",
       "499  bondan winarno yang suka bilang maknyus sekara...          1\n",
       "\n",
       "[500 rows x 2 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# path = './dataset/smsa-document-sentiment/train_preprocess.tsv'\n",
    "# path = './dataset/smsa-document-sentiment/valid_preprocess.tsv'\n",
    "# path = './dataset/smsa-document-sentiment/test_preprocess.tsv'\n",
    "path = './dataset/smsa-document-sentiment/test_preprocess_masked_label.tsv'\n",
    "\n",
    "\n",
    "LABEL2INDEX = {'positive': 0, 'neutral': 1, 'negative': 2}\n",
    "\n",
    "df = pd.read_csv(path, sep='\\t', header=None)\n",
    "df.columns = ['text','sentiment']\n",
    "df['sentiment'] = df['sentiment'].apply(lambda lab: LABEL2INDEX[lab])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6266c84a-4443-49cf-95c5-53647a761e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(os.getcwd() + r'/dataset/smsa-document-sentiment/test_preprocess_masked_label.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "027fee24-f90f-465b-8dc2-c33b8df388c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CUDA_VISIBLE_DEVICES=4 python3 finetuning-adv.py --seed 24032022\n",
    "\n",
    "# CUDA_VISIBLE_DEVICES=5 python3 finetuning-adv.py --seed 26092020\n",
    "\n",
    "# CUDA_VISIBLE_DEVICES=6 python3 finetuning-adv.py --seed 42"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
