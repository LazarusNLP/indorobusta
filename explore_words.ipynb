{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from icecream import ic\n",
    "import numpy as np\n",
    "import math\n",
    "import ast\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pd.read_csv(\"\")\n",
    "\n",
    "\n",
    "\n",
    "# len(dir_list_test)\n",
    "# dir_list_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def wc():\n",
    "\n",
    "seeds = [42, 26092020, 24032022]    \n",
    "path_test = str(os.getcwd()) + \"/result/seed\" + str(42) + \"/\" + \"test\" + \"/\"\n",
    "dir_list_test = [f for f in os.listdir(path_test)]\n",
    "\n",
    "word_candidates = []\n",
    "for seed in seeds:\n",
    "    for f in dir_list_test:\n",
    "        df = pd.read_csv(os.getcwd() + r'/result/seed'+str(seed)+\"/test/\"+str(f))\n",
    "\n",
    "\n",
    "        for el in df['translated_word(s)'].dropna().values:\n",
    "            el = ast.literal_eval(el)\n",
    "            word_candidates.append([(k, v) for k, v in el.items()])\n",
    "\n",
    "merged = list(itertools.chain(*word_candidates))\n",
    "len(merged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"word_candidates.txt\"\n",
    "with open(filename, 'w', encoding=\"utf-8\") as f:\n",
    "    print(merged, file=f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def file_reader(path):\n",
    "    a_file = open(path, \"r\")\n",
    "\n",
    "    vocab = []\n",
    "    for line in a_file:\n",
    "        stripped_line = line.strip()\n",
    "        vocab.append(stripped_line)\n",
    "\n",
    "    a_file.close()\n",
    "    return list(set(vocab))\n",
    "\n",
    "# for lst in file_reader(filename):\n",
    "#     lst = ast.literal_eval(lst)\n",
    "        \n",
    "#     # print(lst)\n",
    "#     for a in lst:\n",
    "#         print(a)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(merged, columns=['word', 'translated'])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"word_candidates.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>translated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>34436</th>\n",
       "      <td>bermasalah</td>\n",
       "      <td>bermasalah</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1194270</th>\n",
       "      <td>ongkos</td>\n",
       "      <td>ongkos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1464729</th>\n",
       "      <td>kode</td>\n",
       "      <td>kode</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>924543</th>\n",
       "      <td>yusmada</td>\n",
       "      <td>yusmada</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304306</th>\n",
       "      <td>suka</td>\n",
       "      <td>suka</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>522934</th>\n",
       "      <td>anak</td>\n",
       "      <td>lanang</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>863112</th>\n",
       "      <td>tagihan</td>\n",
       "      <td>laporan keuangan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1012656</th>\n",
       "      <td>arah</td>\n",
       "      <td>arah</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1044558</th>\n",
       "      <td>respon</td>\n",
       "      <td>respon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1806830</th>\n",
       "      <td>asian</td>\n",
       "      <td>asian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1232944</th>\n",
       "      <td>jokowi</td>\n",
       "      <td>jokowi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24664</th>\n",
       "      <td>nanganin</td>\n",
       "      <td>nanganin</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1021190</th>\n",
       "      <td>tapi</td>\n",
       "      <td>tetapi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515106</th>\n",
       "      <td>tidur</td>\n",
       "      <td>tidur</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91783</th>\n",
       "      <td>banget</td>\n",
       "      <td>banget</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1650732</th>\n",
       "      <td>Gak</td>\n",
       "      <td>Gak</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564091</th>\n",
       "      <td>suka</td>\n",
       "      <td>Comme</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>369798</th>\n",
       "      <td>jamaahnya</td>\n",
       "      <td>jamaahnya</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1849297</th>\n",
       "      <td>suka</td>\n",
       "      <td>mengadili</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1801682</th>\n",
       "      <td>bohong</td>\n",
       "      <td>mentir</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               word        translated\n",
       "34436    bermasalah        bermasalah\n",
       "1194270      ongkos            ongkos\n",
       "1464729        kode              kode\n",
       "924543      yusmada           yusmada\n",
       "304306         suka              suka\n",
       "522934         anak            lanang\n",
       "863112      tagihan  laporan keuangan\n",
       "1012656        arah              arah\n",
       "1044558      respon            respon\n",
       "1806830       asian             asian\n",
       "1232944      jokowi            jokowi\n",
       "24664      nanganin          nanganin\n",
       "1021190        tapi            tetapi\n",
       "515106        tidur             tidur\n",
       "91783        banget            banget\n",
       "1650732         Gak               Gak\n",
       "564091         suka             Comme\n",
       "369798    jamaahnya         jamaahnya\n",
       "1849297        suka         mengadili\n",
       "1801682      bohong            mentir"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"word_candidates.csv\")\n",
    "df.sample(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n=100\n",
    "df_top_hundred = df['word'].value_counts()[:100].to_frame()\n",
    "df_top_hundred.columns = ['count']\n",
    "df_top_hundred.index.names = ['word']\n",
    "df_top_hundred.to_csv(\"top_hundred.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_top_hundred\n",
    "df_top_hundred.to_csv(\"top_hundred.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.8 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "dc07d24e2f18896857f0b2a651fe84ba40ce7b297e58d8804a308c8039f752a6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
